<!DOCTYPE html>
<html>
<head>
    <title>KEC</title>
</head>
<body>
    <h1>Naive Bayes</h1>
    <pre>
        <code>
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import CategoricalNB


file_path = r"C:\Users\matha\Downloads\New folder\dental.csv"
df = pd.read_csv(file_path)

# Display the first 10 rows of the dataset
print("First 10 rows of the dataset:")
print(df.head(10))

# Prepare X and y for training
X = pd.get_dummies(df.iloc[:, :-1])  
y = df.iloc[:, -1]  

model = CategoricalNB()
model.fit(X, y)

input_data = {}
for col in df.columns[:-1]:
    input_data[col] = input(f"Enter {col} ({df[col].unique().tolist()}): ")
input_df = pd.DataFrame([input_data])
input_df = pd.get_dummies(input_df)

input_df = input_df.reindex(columns=X.columns, fill_value=0)

prediction = model.predict(input_df)[0]
print(f"Predicted Dental Health: {prediction}")

print("Explanation: The model predicts dental health based on categorical features.")
        </code>
    </pre>
    <h1>
        KNN
    </h1>
    <pre>
        <code>
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler


df = pd.read_csv(r"C:\Users\matha\Downloads\New folder\diabetes_detection_dataset.csv")

print(df.head())

X = df[["Glucose Level", "BMI", "Age"]]
y = df["Outcome"]

scaler=StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

glucose = float(input("Enter Glucose Level (mg/dL): "))
bmi = float(input("Enter BMI: "))
age = int(input("Enter Age: "))

user_input = scaler.transform([[glucose, bmi, age]])

prediction = knn.predict(user_input)

if prediction[0] == 1:
    print("The person is likely DIABETIC.")
else:
    print("The person is likely NON-DIABETIC.")
        </code>
    </pre>
    <h1>
        Linear Regression
    </h1>
    <pre>
        <code>
import pandas as pd
import matplotlib.pyplot as plt

def calculate_mean(values):
    return sum(values) / len(values)
def linear_regression(x, y):
    mean_x = calculate_mean(x)
    mean_y = calculate_mean(y)

    numerator = sum((x[i] - mean_x) * (y[i] - mean_y) for i in range(len(x)))
    denominator = sum((x[i] - mean_x) ** 2 for i in range(len(x)))

    slope = numerator / denominator
    intercept = mean_y - slope * mean_x

    return slope, intercept

file_path = input("Enter the path to the CSV file (e.g., data.csv): ")
df = pd.read_csv(file_path)

X = df['Altitude'].tolist()
Y = df['Temperature'].tolist()

m, c = linear_regression(X, Y)
print("Slope:", m)
print("Intercept:", c)

x_value = float(input("Enter altitude (m): "))
y_value = m * x_value + c
print("Predicted Temperature:", y_value, "°C")

plt.scatter(X, Y, color='red', label='Data Points')
y_predicted = [m * x + c for x in X]
plt.plot(X, y_predicted, color='blue', label='Regression Line')
plt.xlabel("Altitude (m)")
plt.ylabel("Temperature (°C)")
plt.title("Altitude vs Temperature")
plt.legend()
plt.grid(True)
plt.show()
        </code>
    </pre>
    <h1>SVM</h1>
    <PRE>
        <CODE>
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import classification_report
from matplotlib.lines import Line2D

df = pd.read_csv(r"C:\Users\matha\Downloads\New folder\heart.csv")
X = df[['age', 'chol']]
y = df['output']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

kernels = ['linear', 'poly', 'rbf', 'sigmoid']
scores = {}
for k in kernels:
    model = SVC(kernel=k)
    model.fit(X_train, y_train)
    scores[k] = model.score(X_test, y_test)

best_kernel = max(scores, key=scores.get)
print("Best Kernel:", best_kernel)

final_model = SVC(kernel=best_kernel)
final_model.fit(X_train, y_train)
y_pred = final_model.predict(X_test)
print("\nClassification Report:\n", classification_report(y_test, y_pred))

fig, axs = plt.subplots(2, 2, figsize=(12, 10))
axs = axs.ravel()
xx, yy = np.meshgrid(np.arange(X['age'].min()-1, X['age'].max()+1, 1),
                     np.arange(X['chol'].min()-10, X['chol'].max()+10, 1))

for i, k in enumerate(kernels):
    clf = SVC(kernel=k).fit(X_train, y_train)
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)

    axs[i].contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)
    axs[i].scatter(X_train['age'], X_train['chol'], c=y_train, edgecolors='k', cmap=plt.cm.coolwarm)
    axs[i].set_title(f"{k.capitalize()} Kernel")
    axs[i].set_xlabel("Age")
    axs[i].set_ylabel("Chol")

plt.tight_layout()
plt.show()

def predict_heart(age, chol):
    pred = final_model.predict([[age, chol]])[0]
    return "Disease" if pred == 1 else "No Disease"

print("\nPrediction for Age=54, Chol=240:", predict_heart(54, 354))

        </CODE>
    </PRE>
    <h1>
        K means
    </h1>
    <pre>
        <code>
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

fruits = {
    "Fruit": ['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10'],
    "Sugar": [2, 2, 1, 5, 5, 5, 9, 9, 9, 10],
    "Firmness": [3, 6, 2, 4, 6, 2, 3, 5, 1, 3]
}
df = pd.DataFrame(fruits)

centroids = {
    'C1': [2, 3],
    'C2': [5, 4],
    'C3': [9, 3]
}

colors = {'C1': 'red', 'C2': 'green', 'C3': 'blue'}
markers = {'C1': 'o', 'C2': 's', 'C3': 'D'}

def manhattan_distance(p1, p2):
    return abs(p1[0]-p2[0]) + abs(p1[1]-p2[1])

def assign_clusters(df, centroids):
    cluster_assignment = []
    distance_table = []

    for index, row in df.iterrows():
        fruit_point = (row['Sugar'], row['Firmness'])
        distances = {c: manhattan_distance(fruit_point, pt) for c, pt in centroids.items()}
        cluster_assignment.append(min(distances, key=distances.get))
        distance_table.append(distances)
    return cluster_assignment, distance_table

def update_centroids(df):
    new_centroids = {}
    for cluster in df['Cluster'].unique():
        cluster_points = df[df['Cluster'] == cluster]
        new_centroids[cluster] = [
            cluster_points['Sugar'].mean(),
            cluster_points['Firmness'].mean()
        ]
    return new_centroids

def plot_clusters(df, centroids, iteration, new_point=None):
    plt.figure(figsize=(7, 5))
    for cluster in df['Cluster'].unique():
        clustered_df = df[df['Cluster'] == cluster]
        plt.scatter(clustered_df['Sugar'], clustered_df['Firmness'],
                    c=colors[cluster], label=f"{cluster}", marker=markers[cluster])
    
    for c, (x, y) in centroids.items():
        plt.scatter(x, y, c='black', marker='X', s=150, edgecolor='white', label=f'{c} Center')

    if new_point:
        plt.scatter(new_point[0], new_point[1], c='purple', marker='*', s=150, label='New Point')

    plt.title(f"Cluster Visualization - Iteration {iteration}")
    plt.xlabel("Sugar")
    plt.ylabel("Firmness")
    plt.legend()
    plt.grid(True)
    plt.show()

iteration = 1
prev_clusters = None

while True:
    print(f"\n --- Iteration {iteration} --- ")
    cluster_assignment, distance_table = assign_clusters(df, centroids)

    distance_df = pd.DataFrame(distance_table)
    distance_df.insert(0, 'Fruit', df['Fruit'])
    print("\n Distance Table:")
    print(distance_df)

    df['Cluster'] = cluster_assignment

    print("\nCluster Assignment:")
    print(df[['Fruit', 'Sugar', 'Firmness', 'Cluster']])

    new_centroids = update_centroids(df)

    print("\n Updated Centroids:")
    for c, point in new_centroids.items():
        print(f"{c}: (Sugar: {point[0]:.4f}, Firmness: {point[1]:.4f})")

    plot_clusters(df, new_centroids, iteration)

    if prev_clusters is not None and all(df['Cluster'] == prev_clusters):
        print("\n Clustering converged!")
        break

    centroids = new_centroids
    prev_clusters = df['Cluster'].copy()
    iteration += 1

print("\n Predict a new fruit's cluster!")
new_sugar = float(input("Enter Sugar value: "))
new_firmness = float(input("Enter Firmness value: "))
new_point = (new_sugar, new_firmness)

distances = {c: manhattan_distance(new_point, pt) for c, pt in centroids.items()}
print("\n Distance to Final Centroids:")
for c, d in distances.items():
    print(f"{c}: {d:.4f}")
predicted_cluster = min(distances, key=distances.get)
print(f"\n The new fruit (Sugar={new_sugar}, Firmness={new_firmness}) belongs to: **{predicted_cluster}** ")

plot_clusters(df, centroids, "Final", new_point=new_point)


        </code>
    </pre>
    <h1>
        decision tree
    </h1>
    <pre>
        <code>
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

data = {
'Age': ['<=30', '<=30', '31-40', '>40', '>40'],
'Income': ['High', 'High', 'High', 'Medium', 'Low'],
'Student': ['No', 'No', 'No', 'No', 'Yes'],
'Credit_Rating': ['Fair', 'Excellent', 'Fair', 'Fair', 'Fair'],
'Class': ['No', 'No', 'Yes', 'Yes', 'Yes']
}
df = pd.DataFrame(data)

df = pd.get_dummies(df, columns=['Age', 'Income', 'Student', 'Credit_Rating'], drop_first=True)

X = df.drop(columns=['Class'])
y = df['Class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

dt_model = DecisionTreeClassifier(criterion='entropy', random_state=42)
dt_model.fit(X_train, y_train)

y_pred = dt_model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))

plt.figure(figsize=(10,6))
plot_tree(dt_model, filled=True, feature_names=X.columns, class_names=['No', 'Yes'])
plt.show()

        </code>
    </pre>
    <h1>
        Genetic Algo
    </h1>
    <pre>
        <code>
import random
def crossover(l, q):
l = list(l)
q = list(q)
k = random.randint(0, 15)
print("Crossover point :", k)
for i in range(k, len(s)):
l[i], q[i] = q[i], l[i]
l = ''.join(l)
q = ''.join(q)
print(l)
print(q, "\n\n")
return l, q
s = '1100110110110011' p = '1000110011011111' print("Parents")
print("P1 :", s)
print("P2 :", p, "\n")
for i in range(5):
print("Generation ", i+1, "Childrens :")
s, p = crossover(s, p)
        </code>
    </pre>
    <h1>
        Q Learning
    </h1>
    <pre>
        <code>
import numpy as np
R = np.matrix([ [-1,-1,-1,-1,0,-1],
[-1,-1,-1,0,-1,100],
[-1,-1,-1,0,-1,-1],
[-1,0,0,-1,0,-1],
[-1,0,0,-1,-1,100],
[-1,0,-1,-1,0,100] ])

Q = np.matrix(np.zeros([6,6]))
gamma = 0.8

initial_state = 1
def available_actions(state):
current_state_row = R[state,]
av_act = np.where(current_state_row >= 0)[1]
return av_act
available_act = available_actions(initial_state)
def sample_next_action(available_actions_range):
next_action = int(np.random.choice(available_act,1))
return next_action
action = sample_next_action(available_act)
def update(current_state, action, gamma):
max_index = np.where(Q[action,] == np.max(Q[action,]))[1]
if max_index.shape[0] > 1:
max_index = int(np.random.choice(max_index, size = 1))
else:
max_index = int(max_index)
max_value = Q[action, max_index]
Q[current_state, action] = R[current_state, action] + gamma * max_value
update(initial_state,action,gamma)
for i in range(10000):
current_state = np.random.randint(0, int(Q.shape[0]))
available_act = available_actions(current_state)
action = sample_next_action(available_act)
update(current_state,action,gamma)
print("Trained Q matrix:")
print(Q/np.max(Q)*100)
current_state = 2
steps = [current_state]
while current_state != 5:
next_step_index = np.where(Q[current_state,] == np.max(Q[current_state,]))[1]
if next_step_index.shape[0] > 1:
next_step_index = int(np.random.choice(next_step_index, size = 1))
else:
next_step_index = int(next_step_index)
steps.append(next_step_index)
current_state = next_step_index
print("Selected path:")
print(steps)
        </code>
    </pre>
</body>
</html>